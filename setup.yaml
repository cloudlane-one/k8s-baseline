- name: Add all hosts to known_hosts file, if according flag is set
  hosts: localhost
  connection: local
  tags: cluster
  tasks:
    - name: Add all hosts to known_hosts file
      when: "auto_trust_remotes == true"
      block:
        - name: Check whether host is already known
          loop: "{{ groups['k3s_cluster'] }}"
          ansible.builtin.command: "ssh-keygen -F {{ hostvars[item].ansible_host }}"
          changed_when: false
          failed_when: false
          ignore_errors: true
          register: known_hosts_check

        - name: Generate new lines for known_hosts
          loop: "{{ known_hosts_check.results }}"
          when: "item.rc != 0"
          ansible.builtin.command: "ssh-keyscan -H {{ hostvars[item.item].ansible_host }}"
          register: known_hosts_entries

        - name: Add lines to known_hosts
          when: "known_hosts_entries.changed == true"
          loop: "{{ known_hosts_entries.results }}"
          lineinfile:
            dest: ~/.ssh/known_hosts
            line: "{{ item.stdout }}"
            insertafter: EOF

- name: Install k3s on all cluster nodes and bootstrap infrastructure
  hosts: k3s_cluster
  become: true
  tags: cluster
  vars:
    k3s_become: true
    k3s_etcd_datastore: true
    k3s_install_hard_links: true
    k3s_server:
      node-taint:
        - "node.cilium.io/agent-not-ready=true:NoExecute"
      flannel-backend: "none"
      disable:
        - traefik
        - local-storage
      kube-apiserver-arg:
        - "oidc-issuer-url=https://{{ (helm_values.subdomains | default({})).dex | default('admin-oidc') }}.{{ helm_values.domain }}"
        - "oidc-client-id=admin-oidc"
        - "oidc-groups-claim=groups"
    k3s_agent:
      node-taint:
        - "node.cilium.io/agent-not-ready=true:NoExecute"
  tasks:
    - name: Set control_node variable for master hosts
      ansible.builtin.set_fact:
        k3s_control_node: true
      when: "'masters' in group_names"

    - name: Ensure NFS client is installed (apt)
      ansible.builtin.apt:
        name: nfs-common
        update_cache: yes
      when: 'ansible_pkg_mgr == "apt"'

    - name: Ensure NFS client is installed (yum)
      ansible.builtin.apt:
        name: nfs-utils
        update_cache: yes
      when: 'ansible_pkg_mgr == "yum"'

    - name: Ensure NFS client is installed (apk)
      community.general.apk:
        name: nfs-utils
        update_cache: yes
      when: 'ansible_pkg_mgr == "apk"'

    - name: Ensure NFS client is installed (dnf)
      ansible.builtin.dnf:
        name: nfs-utils
        update_cache: yes
      when: 'ansible_pkg_mgr == "dnf"'

    - name: Ensure NFS client is installed (zypper)
      community.general.zypper:
        name: nfs-utils
        update_cache: yes
      when: 'ansible_pkg_mgr == "zypper"'

    - name: Ensure NFS client is installed (pacman)
      community.general.pacman:
        name: nfs-utils
        update_cache: yes
      when: 'ansible_pkg_mgr == "pacman"'

    - name: Install k3s via role
      ansible.builtin.include_role:
        name: xanmanning.k3s

- name: Set up GitOps for cluster infrastructure via FluxCD
  hosts: masters
  run_once: true
  tags: infra
  environment:
    K8S_AUTH_KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  tasks:
    - name: Ensure PIP is installed
      ansible.builtin.package:
        name: pip

    - name: Copy requirements.txt to remote
      ansible.builtin.copy:
        src: requirements.txt
        dest: /tmp

    - name: Ensure PIP dependencies are installed
      ansible.builtin.pip:
        requirements: /tmp/requirements.txt

    - name: Check if Helm CLI is installed
      ansible.builtin.shell: "which helm"
      register: which_helm
      changed_when: false
      failed_when: false
      ignore_errors: true

    - name: Download Helm install script
      when: "which_helm.rc != 0"
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        dest: /tmp/helm-install.sh
        mode: "0700"

    - name: Run Helm install script
      when: "which_helm.rc != 0"
      ansible.builtin.command: /tmp/helm-install.sh

    - name: Ensure helm diff plugin is installed
      kubernetes.core.helm_plugin:
        plugin_path: https://github.com/databus23/helm-diff

    - name: Copy values files for bootstrap helm charts
      ansible.builtin.copy:
        src: infrastructure/bootstrap-values
        dest: /tmp

    - name: Ensure required namespaces exist
      kubernetes.core.k8s:
        wait: true
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: "{{ item }}"
            labels:
              "app.kubernetes.io/managed-by": "Helm"
            annotations:
              "meta.helm.sh/release-name": "k8s-baseline"
              "meta.helm.sh/release-namespace": "flux-system"
      with_items:
        - backup-system
        - cert-system
        - flux-system
        - ingress-system
        - longhorn-system
        - o11y-system

    - name: Check whether HelmRelease for infrastraucture chart already exists
      kubernetes.core.k8s_info:
        api_version: helm.toolkit.fluxcd.io/v2beta1
        kind: HelmRelease
        name: k8s-baseline
        namespace: flux-system
      register: k8s_baseline_release

    - name: Ensure Cilium is installed
      when: "(k8s_baseline_release.resources | length) == 0"
      kubernetes.core.helm:
        wait: true
        name: cilium
        release_namespace: kube-system
        chart_repo_url: https://helm.cilium.io/
        chart_ref: cilium
        chart_version: "^1"
        values_files:
          - /tmp/bootstrap-values/cilium.yaml

    - name: Restore from full-cluster backup
      when: restore_from_backup is defined
      block:
        - name: Ensure Velero backup secret exists
          kubernetes.core.k8s:
            wait: true
            definition:
              apiVersion: v1
              kind: Secret
              metadata:
                name: s3-backup-credentials
                namespace: backup-system
              type: Opaque
              data:
                cloud: '{{ ("[default]\naws_access_key_id=" helm_values.s3.access_key.id + "\naws_secret_access_key=" + helm_values.s3.access_key.secret) | b64encode  }}'

        - name: Ensure Velero is installed
          kubernetes.core.helm:
            wait: true
            name: velero
            release_namespace: backup-system
            chart_repo_url: https://vmware-tanzu.github.io/helm-charts/
            chart_ref: velero
            chart_version: "^2"
            values:
              credentials:
                existingSecret: s3-backup-credentials
              initContainers:
                - name: velero-plugin-for-csi
                  image: velero/velero-plugin-for-csi:v0.3.0
                  imagePullPolicy: IfNotPresent
                  volumeMounts:
                    - mountPath: /target
                      name: plugins
                - name: velero-plugin-for-aws
                  image: velero/velero-plugin-for-aws:v1.5.0
                  imagePullPolicy: IfNotPresent
                  volumeMounts:
                    - mountPath: /target
                      name: plugins
              snapshotsEnabled: true
              configuration:
                provider: aws
                features: EnableCSI
                backupStorageLocation:
                  name: default
                  bucket: "{{ helm_values.s3.buckets.backup }}"
                  prefix: velero
                  config:
                    region: "{{ helm_values.s3.region }}"
                    s3Url: "https://{{ helm_values.s3.endpoint }}"
                volumeSnapshotLocation:
                  name: default
                  config:
                    region: "{{ helm_values.s3.region }}"

        - name: Apply backup restoration
          kubernetes.core.k8s:
            wait: true
            definition:
              apiVersion: velero.io/v1
              kind: Restore
              metadata:
                name: initial-cluster-restore
                namespace: backup-system
              spec:
                backupName: "{{ restore_from_backup }}"

    - name: Bootstrap infrastructure
      when: (restore_from_backup is undefined) and ((k8s_baseline_release.resources | length) == 0)
      block:
        - name: Ensure Cert-Manager is installed
          kubernetes.core.helm:
            wait: true
            name: cert-manager
            release_namespace: cert-system
            chart_repo_url: https://charts.jetstack.io
            chart_ref: cert-manager
            chart_version: "^1"
            values_files:
              - /tmp/bootstrap-values/cert-manager.yaml

        - name: Ensure FluxCD is installed
          kubernetes.core.helm:
            wait: true
            name: fluxcd
            release_namespace: flux-system
            chart_repo_url: https://fluxcd-community.github.io/helm-charts
            chart_ref: flux2
            chart_version: "^1"
            values_files:
              - /tmp/bootstrap-values/fluxcd.yaml

        - name: Ensure Longhorn is installed
          kubernetes.core.helm:
            wait: true
            name: longhorn
            release_namespace: longhorn-system
            chart_repo_url: https://charts.longhorn.io
            chart_ref: longhorn
            chart_version: "^1"
            values_files:
              - /tmp/bootstrap-values/longhorn.yaml

        - name: Ensure Kube-Prometheus-Stack is installed
          kubernetes.core.helm:
            wait: true
            name: kube-prometheus-stack
            release_namespace: o11y-system
            chart_repo_url: https://prometheus-community.github.io/helm-charts
            chart_ref: kube-prometheus-stack
            chart_version: "^40"
            values_files:
              - /tmp/bootstrap-values/kube-prometheus-stack.yaml

        - name: Ensure Ingress-NGINX is installed
          kubernetes.core.helm:
            wait: true
            name: ingress-nginx
            release_namespace: ingress-system
            chart_repo_url: https://kubernetes.github.io/ingress-nginx
            chart_ref: ingress-nginx
            chart_version: "^4"
            values_files:
              - /tmp/bootstrap-values/ingress-nginx.yaml

        - name: Ensure temp manifest download dir exists
          ansible.builtin.file:
            path: /tmp/bootstrap-manifests/
            state: directory
            mode: "0755"

        - name: Download VolumeSnapshot CRDs
          ansible.builtin.get_url:
            url: "https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.1/client/config/crd/{{ item }}"
            dest: /tmp/bootstrap-manifests/
            mode: "0664"
          with_items:
            - snapshot.storage.k8s.io_volumesnapshotclasses.yaml
            - snapshot.storage.k8s.io_volumesnapshotcontents.yaml
            - snapshot.storage.k8s.io_volumesnapshots.yaml

        - name: Ensure VolumeSnapshot CRDs are installed
          kubernetes.core.k8s:
            wait: true
            namespace: backup-system
            src: "/tmp/bootstrap-manifests/{{ item }}"
          with_items:
            - snapshot.storage.k8s.io_volumesnapshotclasses.yaml
            - snapshot.storage.k8s.io_volumesnapshotcontents.yaml
            - snapshot.storage.k8s.io_volumesnapshots.yaml

        - name: Download VolumeSnapshot controller manifests
          ansible.builtin.get_url:
            url: "https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/release-6.1/deploy/kubernetes/snapshot-controller/{{ item }}"
            dest: /tmp/bootstrap-manifests/
            mode: "0664"
          with_items:
            - rbac-snapshot-controller.yaml
            - setup-snapshot-controller.yaml

        - name: Ensure VolumeSnapshot controller is installed
          kubernetes.core.k8s:
            wait: true
            namespace: backup-system
            src: "/tmp/bootstrap-manifests/{{ item }}"
          with_items:
            - rbac-snapshot-controller.yaml
            - setup-snapshot-controller.yaml

        - name: Download System Upgrade controller manifests
          ansible.builtin.get_url:
            url: https://github.com/rancher/system-upgrade-controller/releases/latest/download/system-upgrade-controller.yaml
            dest: /tmp/bootstrap-manifests/
            mode: "0664"

        - name: Ensure System Upgrade controller is installed
          kubernetes.core.k8s:
            wait: true
            namespace: kube-system
            src: /tmp/bootstrap-manifests/system-upgrade-controller.yaml

    - name: Check if Longhorn volume encryption secret exists
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Secret
        name: longhorn-crypto
        namespace: longhorn-system
      register: longhorn_crypto_secret

    - name: Create Longhorn volume encryption secret
      when: "(longhorn_crypto_secret.resources | length) == 0"
      kubernetes.core.k8s:
        wait: true
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: longhorn-crypto
            namespace: longhorn-system
          stringData:
            CRYPTO_KEY_VALUE: "{{ lookup('ansible.builtin.password', '/tmp/passwordfile chars=ascii_letters') }}"
            CRYPTO_KEY_PROVIDER: "secret"
            CRYPTO_KEY_CIPHER: "aes-xts-plain64"
            CRYPTO_KEY_HASH: "sha256"
            CRYPTO_KEY_SIZE: "256"
            CRYPTO_PBKDF: "argon2i"

    - name: Ensure Longhorn crypto storage class exists
      kubernetes.core.k8s:
        wait: true
        definition:
          kind: StorageClass
          apiVersion: storage.k8s.io/v1
          metadata:
            name: longhorn-crypto
            annotations:
              "storageclass.kubernetes.io/is-default-class": "true"
          provisioner: driver.longhorn.io
          allowVolumeExpansion: true
          parameters:
            numberOfReplicas: "2"
            staleReplicaTimeout: "2880" # 48 hours in minutes
            fromBackup: ""
            encrypted: "true"
            # global secret that contains the encryption key that will be used for all volumes
            csi.storage.k8s.io/provisioner-secret-name: "longhorn-crypto"
            csi.storage.k8s.io/provisioner-secret-namespace: "longhorn-system"
            csi.storage.k8s.io/node-publish-secret-name: "longhorn-crypto"
            csi.storage.k8s.io/node-publish-secret-namespace: "longhorn-system"
            csi.storage.k8s.io/node-stage-secret-name: "longhorn-crypto"
            csi.storage.k8s.io/node-stage-secret-namespace: "longhorn-system"

    - name: Ensure GitRepository for infrastructure chart exists
      kubernetes.core.k8s:
        wait: true
        definition:
          apiVersion: source.toolkit.fluxcd.io/v1beta2
          kind: GitRepository
          metadata:
            name: k8s-baseline
            namespace: flux-system
          spec:
            interval: 1h
            url: "{{ gitops_repo }}"
            ref:
              branch: "{{ gitops_branch }}"

    - name: Ensure HelmRelease for infrastructure chart exists
      kubernetes.core.k8s:
        wait: true
        definition:
          apiVersion: helm.toolkit.fluxcd.io/v2beta1
          kind: HelmRelease
          metadata:
            name: k8s-baseline
            namespace: flux-system
          spec:
            interval: 1h
            chart:
              spec:
                chart: ./infrastructure
                sourceRef:
                  kind: GitRepository
                  name: k8s-baseline
                reconcileStrategy: Revision
            values: "{{ helm_values }}"
